---
published: false
title: Pipeline do scikit-learn
excerpt: "Pipeline do scikit-learn"
header:
  image: /assets/images/seek.jpg
categories: [code]
tags: [pipeline]
---
A nossa lib favorita,
[scikit-learn](http://scikit-learn.org/), tem várias funções
para facilitar nossa vida. É quase uma filosofia de trabalho. Hoje nós vamos falar
da função pipeline que, na minha opinião, alinha muito com a filosofia do
[cookie cutter data science](https://drivendata.github.io/cookiecutter-data-science/).
A ideia de todo projeto cookie cutter é ter um padrão pronto pra vc começar a
trabalhar em cima, por isso o nome cortador de biscoisto, é uma forma, todos
biscoitinhos vão sair iguais.

O cookiecutter de DS é bem legal e a idea é se ajustar para suas necessidades. A
parte que eu mais gosto é a
 [filosofia](https://drivendata.github.io/cookiecutter-data-science/#opinions)
que ele sugere. Alguns pontos dessa filosofiaa
são seguidos por pacotes como o scikit ou mesmo Spark (Spark ML se inspira na 
estrutura do scikit). Entre elas está:

## Dados são imutáveis
A ideia é que você não deve editar seus dados brutos. Quem fez isso já sabe que
não é uma boa ideia. Pra você que não fez imagina que se você abrir seus dados
brutos no excel pra tirar os acentos, por exemplo, daqui a três meses alguém tenta usar seu código
nos dados originais e não funciona. Ou mesmo, você precisa apresentar seus resultados
mas tudo sai sem acento. Meu exemplo não parece tão trágico, mas isso da problema.

A ideia é que seu código pegue os dados brutos e faça todas as tranformações e 
"análise" até entregar os resultados. Assim você não tem versionamento dos seus
dados brutos e facilita a replicação dos seus resultados por terceiros.

Quem é de TI já ouviu falar de pipeline. A ideia é que você pegue seus dados brutos,
passe ele numa pipeline, um gasoduto : P, até entregar o resultado no final.
O scikit tem uma
 [função Pipeline](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)
que nos ajuda exatamente nisso. Vamos dar uma olhada.

## [Pipeline](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)

A princípio, se você olhar a documentação dessa função ela parece bem minimalista.
Só temos dois parâmetros, *steps* e *memory*. Nesse post a gente não vai entrar em tanto
detalhe sobre o *memory* nesse post, mas a ideia é que ele permite o caching dos transformadores.

O principal é o *steps*. Esse argumento tem que ser uma lista de tuplas. Tuplas 
são aqueles pares (ou mais) de arguementos. No caso a nossa tupla tem que ser o
nome do passo e a função desse passo. Por exemplo, quero fazer um PCA nos meus dados
eu posso colocar a tupla ```('Passo_1_PCA',PCA())``` como o primeiro item dessa lista.

Vamos fazer um exemplo rápido pra dar uma ideia de como usar a Pipeline. Como sempre
esse exemplo de código está no meu github
 [nesse link](https://github.com/gusrabbit/blog-examples/blob/master/Pipeline.ipynb)
